{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we cover how to train Mask R-CNN+ using the Matterport implementation of Mask R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import imgaug as iaa\n",
    "import skimage.io\n",
    "import keras.callbacks\n",
    "\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(os.getcwd())\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from mrcnn.config import Config\n",
    "\n",
    "\n",
    "import Monuseg\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "MONUSEG_DIR = os.path.join(ROOT_DIR, \"datasets\", \"MoNuSeg\")\n",
    "\n",
    "# Comment out to reload imported modules if they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define augmentations, we only use light augmentations during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up augmentation, additional targets for dist and H-channels of image:\n",
    "# (Treated as mask-type for the putposes of applying augmentations to prevent intenssity disturbances)\n",
    "augmentation =  A.Compose([\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, brightness_by_max=True, p=0.4),\n",
    "    A.HorizontalFlip(always_apply=False, p=0.5),\n",
    "    A.VerticalFlip(always_apply=False, p=0.5),\n",
    "    A.Rotate(limit = 359, always_apply=False, p=0.5),\n",
    "], p=1,\n",
    "    additional_targets={'dist': 'mask', 'Hch': 'mask'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up all variables needed for training. \\\n",
    "Hyperparameters can be found and altered in the MoNuSeg.MoNuSegConfig() class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            5\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  256\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              crop\n",
      "IMAGE_SHAPE                    [256 256   5]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               400\n",
      "MEAN_PIXEL                     [176.31886506 115.74123431 155.43802069  15.18166894 123.7591    ]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           MoNuSeg_Coco\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.4\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.8\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                60\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           600\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               0\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Found 30 images in C:\\Users\\User\\GitHub\\Improved Mask R-CNN\\datasets\\MoNuSeg\\train\\tissue_images\n"
     ]
    }
   ],
   "source": [
    "# Set up variables for training\n",
    "config = Monuseg.MonusegConfig()\n",
    "config.NAME = \"MoNuSeg_Coco\"\n",
    "config.display()\n",
    "\n",
    "DEVICE = \"/gpu:0\"\n",
    "TEST_MODE = \"training\" #\"inference\" or \"training\"\n",
    "\n",
    "dataset_dir = MONUSEG_DIR\n",
    "subset = \"train\"\n",
    "dataset_dir = os.path.join(dataset_dir, subset)\n",
    "image_dir = os.path.join(dataset_dir, \"tissue_images\")\n",
    "image_ids = os.listdir(image_dir)\n",
    "print(\"Found {} images in {}\".format(len(image_ids), image_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model, load weights, set up dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\User\\GitHub\\Improved Mask R-CNN\\mrcnn\\model.py:561: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\GitHub\\Improved Mask R-CNN\\mrcnn\\utils.py:204: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\GitHub\\Improved Mask R-CNN\\mrcnn\\model.py:608: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "Loding model from: C:\\Users\\User\\GitHub\\Improved Mask R-CNN\\mask_rcnn_coco.h5\n",
      "Model name: MoNuSeg_Coco\n",
      "Have 30 train images\n",
      "Have 1 val images\n"
     ]
    }
   ],
   "source": [
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=TEST_MODE, model_dir=MODEL_DIR, config=config, verbose = False)\n",
    "\n",
    "weights_path = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "print(\"Loding model from: {}\".format(weights_path))\n",
    "\n",
    "#Exclude COCO heads\n",
    "model.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "#model.load_weights(weights_path, by_name=True)\n",
    "print(\"Model name: {}\".format(config.NAME))\n",
    "\n",
    "# Set up Datasets Objects \n",
    "dataset_train = Monuseg.MonusegDataset()\n",
    "dataset_val = Monuseg.MonusegDataset()\n",
    "dataset_train.add_class(source = \"Monuseg\", class_id =  1, class_name = \"nucleus\")\n",
    "dataset_val.add_class(source = \"Monuseg\", class_id =  1, class_name = \"nucleus\")\n",
    "\n",
    "# Fill with the samples\n",
    "i = 0\n",
    "for _id in image_ids:\n",
    "    name,_ = os.path.splitext(_id)\n",
    "    if i <= len(image_ids):\n",
    "        dataset_train.add_image(source = \"Monuseg\",\n",
    "                                image_id = name,\n",
    "                                path = os.path.join(image_dir, _id))\n",
    "    i+=1\n",
    "\n",
    "\n",
    "dataset_val.add_image(source = \"Monuseg\",\n",
    "                                image_id = name,\n",
    "                                path = os.path.join(image_dir, _id))\n",
    "    \n",
    "\n",
    "\n",
    "dataset_val.prepare()\n",
    "dataset_train.prepare()\n",
    "\n",
    "print(\"Have {} train images\".format(len(dataset_train.image_ids)))\n",
    "print(\"Have {} val images\".format(len(dataset_val.image_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.0002\n",
      "\n",
      "Checkpoint Path: C:\\Users\\User\\GitHub\\Improved Mask R-CNN\\logs\\monuseg_coco20210802T1430\\mask_rcnn_monuseg_coco_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "PREPROC                (Conv2D)\n",
      "conv1                  (Conv2D)\n",
      "In model:  rpn_model\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/5\n",
      "60/60 [==============================] - 80s 1s/step - loss: 4.0335 - rpn_class_loss: 0.8694 - rpn_bbox_loss: 1.7897 - mrcnn_class_loss: 0.1280 - mrcnn_bbox_loss: 0.6789 - mrcnn_mask_loss: 0.5674 - val_loss: 3.3231 - val_rpn_class_loss: 1.0195 - val_rpn_bbox_loss: 1.1962 - val_mrcnn_class_loss: 0.0872 - val_mrcnn_bbox_loss: 0.5364 - val_mrcnn_mask_loss: 0.4838\n",
      "Epoch 2/5\n",
      "13/60 [=====>........................] - ETA: 1:10 - loss: 3.6763 - rpn_class_loss: 0.9550 - rpn_bbox_loss: 1.5568 - mrcnn_class_loss: 0.0436 - mrcnn_bbox_loss: 0.6209 - mrcnn_mask_loss: 0.4999"
     ]
    }
   ],
   "source": [
    "# Optimal stage-based training\n",
    "model.train(dataset_train, dataset_val,\n",
    "       learning_rate=config.LEARNING_RATE*2,\n",
    "        epochs=5,\n",
    "        augmentation=augmentation,\n",
    "        layers=r\"(PREPROC.*)|(conv1.*)|(mrcnn\\_.*)\")\n",
    "\n",
    "#model.train(dataset_train, dataset_val,\n",
    "#       learning_rate=config.LEARNING_RATE,\n",
    "#        epochs=5+35,\n",
    "#        augmentation=augmentation,\n",
    "#        layers=\"all\")\n",
    "\n",
    "#model.train(dataset_train, dataset_val,\n",
    "#       learning_rate=config.LEARNING_RATE * 0.5,\n",
    "#        epochs=40+5,\n",
    "#        augmentation=augmentation,\n",
    "#        layers='5+')\n",
    "\n",
    "#model.train(dataset_train, dataset_val,\n",
    "#       learning_rate=config.LEARNING_RATE * 0.1,\n",
    "#        epochs=45+5,\n",
    "#        augmentation=augmentation,\n",
    "#        layers='heads')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_dir = MONUSEG_DIR\n",
    "subset = \"train\"\n",
    "dataset_dir = os.path.join(dataset_dir, subset)\n",
    "    \n",
    "dict_names = {}\n",
    "\n",
    "image_dir = os.path.join(dataset_dir, \"tissue_images\")\n",
    "image_ids = os.listdir(image_dir)\n",
    "# Fill with the samples\n",
    "for _id in image_ids:\n",
    "    name,_ = os.path.splitext(_id)\n",
    "    dict_names[name] = os.path.join(image_dir, _id)\n",
    "\n",
    "print(image_dir)\n",
    "for k in dict_names.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixture = 2x Bladder, Colon, Stomach\n",
    "# 1: Kidney, Mixture, Liver, Prostate (No Breast)\n",
    "# 2: Mixture, Liver, Prostate, Breast (No Kidney)\n",
    "# 3: Liver, Prostate, Breast, Kidney (No Mixture)\n",
    "# 4: Prostate, Breast, Kidney, Mixture (No Liver)\n",
    "# 5: Breast, Kidney, Mixture, Liver (No Prostate) \n",
    "\n",
    "organ_dict = {\n",
    "\"Breast\":[\"TCGA-A7-A13E-01Z-00-DX1\",\n",
    "    \"TCGA-A7-A13F-01Z-00-DX1\",\n",
    "    \"TCGA-AR-A1AK-01Z-00-DX1\",\n",
    "    \"TCGA-AR-A1AS-01Z-00-DX1\",\n",
    "    \"TCGA-E2-A14V-01Z-00-DX1\",\n",
    "    \"TCGA-E2-A1B5-01Z-00-DX1\"],\n",
    "\"Kidney\":[\"TCGA-B0-5698-01Z-00-DX1\",\n",
    "    \"TCGA-B0-5710-01Z-00-DX1\",\n",
    "    \"TCGA-B0-5711-01Z-00-DX1\",\n",
    "    \"TCGA-HE-7128-01Z-00-DX1\",\n",
    "    \"TCGA-HE-7129-01Z-00-DX1\",\n",
    "    \"TCGA-HE-7130-01Z-00-DX1\"],\n",
    "\"Liver\":[\"TCGA-18-5592-01Z-00-DX1\",\n",
    "    \"TCGA-21-5784-01Z-00-DX1\",\n",
    "    \"TCGA-21-5786-01Z-00-DX1\",\n",
    "    \"TCGA-38-6178-01Z-00-DX1\",\n",
    "    \"TCGA-49-4488-01Z-00-DX1\",\n",
    "    \"TCGA-50-5931-01Z-00-DX1\"],\n",
    "\"Prostate\":[\"TCGA-CH-5767-01Z-00-DX1\",\n",
    "    \"TCGA-G9-6336-01Z-00-DX1\",\n",
    "    \"TCGA-G9-6348-01Z-00-DX1\",\n",
    "    \"TCGA-G9-6356-01Z-00-DX1\",\n",
    "    \"TCGA-G9-6362-01Z-00-DX1\",\n",
    "    \"TCGA-G9-6363-01Z-00-DX1\"],\n",
    "\"Mixture\":[\"TCGA-KB-A93J-01A-01-TS1\",\n",
    "    \"TCGA-RD-A8N9-01A-01-TS1\",\n",
    "    \"TCGA-AY-A8YK-01A-01-TS1\",\n",
    "    \"TCGA-NH-A8F7-01A-01-TS1\",\n",
    "    \"TCGA-DK-A2I6-01A-01-TS1\",\n",
    "    \"TCGA-G2-A2EK-01A-02-TSB\"]\n",
    "}\n",
    "\n",
    "fold1 = []\n",
    "for k in [\"Kidney\", \"Liver\", \"Prostate\", \"Mixture\"]:\n",
    "    fold1.extend(organ_dict[k])\n",
    "\n",
    "fold2 = []\n",
    "for k in [\"Mixture\", \"Liver\", \"Prostate\", \"Breast\"]:\n",
    "    fold2.extend(organ_dict[k])\n",
    "\n",
    "fold3 = []\n",
    "for k in [\"Liver\", \"Prostate\", \"Breast\", \"Kidney\"]:\n",
    "    fold3.extend(organ_dict[k])\n",
    "    \n",
    "fold4 = []\n",
    "for k in [\"Prostate\", \"Breast\", \"Kidney\", \"Mixture\"]:\n",
    "    fold4.extend(organ_dict[k])\n",
    "    \n",
    "fold5 = []\n",
    "for k in [\"Breast\", \"Kidney\", \"Mixture\", \"Liver\"]:\n",
    "    fold5.extend(organ_dict[k])\n",
    "    \n",
    "       \n",
    "fold_list = [fold1, fold2, fold3, fold4, fold5]\n",
    "for f in fold_list:\n",
    "    print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = Monuseg.MonusegConfig()\n",
    "config.VALIDATION_STEPS = 0\n",
    "i = 0\n",
    "\n",
    "for fold in fold_list:\n",
    "    # Used to choose model fold number\n",
    "    if i == 2:   \n",
    "        print(\"Model Nr. {} Fold:\".format(i))\n",
    "        print(fold)\n",
    "        dataset_train = Monuseg.MonusegDataset()\n",
    "        dataset_val = Monuseg.MonusegDataset()\n",
    "        dataset_train.add_class(\"Monuseg\", 1, \"nucleus\")\n",
    "        # Fill with the train samples\n",
    "        for _n in fold:\n",
    "            dataset_train.add_image(source = \"Monuseg\", image_id = _n, path = dict_names[_n])\n",
    "        dataset_train.prepare()\n",
    "        \n",
    "        config.NAME = \"Monuseg_5Fold_COCO_\" + str(i)\n",
    "        \n",
    "        with tf.device(DEVICE):\n",
    "            model = modellib.MaskRCNN(mode=TEST_MODE, model_dir=MODEL_DIR, config=config, verbose = False)\n",
    "        \n",
    "        wp = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "        \n",
    "        print(\"Loding model from: {}\".format(wp))\n",
    "        model.load_weights(wp, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                \"mrcnn_bbox\", \"mrcnn_mask\"])        \n",
    "        \n",
    "        \n",
    "        model.train(dataset_train, dataset_val,\n",
    "               learning_rate=config.LEARNING_RATE*2,\n",
    "                epochs=5,\n",
    "                augmentation=augmentation,\n",
    "                layers=r\"(PREPROC.*)|(conv1.*)|(mrcnn\\_.*)\")\n",
    "\n",
    "        #model.train(dataset_train, dataset_val,\n",
    "        #       learning_rate=config.LEARNING_RATE,\n",
    "        #        epochs=5+35,\n",
    "        #        augmentation=augmentation,\n",
    "        #        layers=\"all\")\n",
    "\n",
    "        #model.train(dataset_train, dataset_val,\n",
    "        #       learning_rate=config.LEARNING_RATE * 0.5,\n",
    "        #        epochs=40+5,\n",
    "        #        augmentation=augmentation,\n",
    "        #        layers='5+')\n",
    "\n",
    "        #model.train(dataset_train, dataset_val,\n",
    "        #       learning_rate=config.LEARNING_RATE * 0.1,\n",
    "        #        epochs=45+5,\n",
    "        #        augmentation=augmentation,\n",
    "        #        layers='heads')\n",
    "\n",
    "\n",
    "\n",
    "        del model\n",
    "    i = i+1        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
