{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import albumentations as A\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import imgaug as iaa\n",
    "import skimage.io\n",
    "import keras.callbacks\n",
    "\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(os.getcwd())\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "from mrcnn.config import Config\n",
    "\n",
    "\n",
    "import Monuseg_dist\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "MONUSEG_DIR = os.path.join(ROOT_DIR, \"datasets\", \"MoNuSeg_Dist\")\n",
    "\n",
    "# Comment out to reload imported modules if they change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up augmentation, additional target for dist channel of image:\n",
    "# (Treated as mask-type for the putposes of applying augmentations)\n",
    "augmentation =  A.Compose([\n",
    "    #A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=False, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, brightness_by_max=True, p=0.4),\n",
    "#    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.1),\n",
    "    A.HorizontalFlip(always_apply=False, p=0.5),\n",
    "    A.VerticalFlip(always_apply=False, p=0.5),\n",
    "    A.Rotate(limit = 359, always_apply=False, p=0.5),\n",
    "], p=1,\n",
    "    additional_targets={'dist': 'mask', 'Hch': 'mask'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        400\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            5\n",
      "IMAGE_MAX_DIM                  256\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  256\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              crop\n",
      "IMAGE_SHAPE                    [256 256   5]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.0001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               400\n",
      "MEAN_PIXEL                     [176.31886506 115.74123431 155.43802069  15.18166894 123.7591    ]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           MoNuSeg_Coco_Opttrain_DISTH_tissue\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.4\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.8\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                60\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           600\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               0\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Found 30 images in C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\datasets\\MoNuSeg_Dist\\train\\tissue_images\n"
     ]
    }
   ],
   "source": [
    "# Set up variables for training\n",
    "config = Monuseg_dist.MonusegDIST_HConfig()\n",
    "config.NAME = \"MoNuSeg_Coco_Opttrain_DISTH_tissue\"\n",
    "config.VALIDATION_STEPS = 0\n",
    "config.display()\n",
    "\n",
    "DEVICE = \"/gpu:0\"\n",
    "TEST_MODE = \"training\" #\"inference\" or \"training\"\n",
    "\n",
    "dataset_dir = MONUSEG_DIR\n",
    "subset = \"train\"\n",
    "dataset_dir = os.path.join(dataset_dir, subset)\n",
    "image_dir = os.path.join(dataset_dir, \"tissue_images\")\n",
    "image_ids = os.listdir(image_dir)\n",
    "print(\"Found {} images in {}\".format(len(image_ids), image_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\datasets\\MoNuSeg_Dist\\train\\tissue_images\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\mrcnn\\model.py:559: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\mrcnn\\utils.py:203: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\mrcnn\\model.py:606: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "Loding model from: C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\mask_rcnn_coco.h5\n",
      "Model name: MoNuSeg_Coco_Opttrain_DISTH_tissue\n",
      "Have 30 train images\n",
      "Have 1 val images\n"
     ]
    }
   ],
   "source": [
    "# Create the model, load weights\n",
    "dataset_dir = MONUSEG_DIR\n",
    "subset = \"train\"\n",
    "dataset_dir = os.path.join(dataset_dir, subset)\n",
    "image_dir = os.path.join(dataset_dir, \"tissue_images\")\n",
    "image_ids = os.listdir(image_dir)\n",
    "print(\"Loading data from: \", image_dir)\n",
    "\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=TEST_MODE, model_dir=MODEL_DIR, config=config, verbose = False)\n",
    "\n",
    "#weights_path = model.find_last()\n",
    "weights_path = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "#weights_path = r\"C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\logs\\pannuke model20210622T1625\\mask_rcnn_pannuke model_0036.h5\"\n",
    "\n",
    "\n",
    "print(\"Loding model from: {}\".format(weights_path))\n",
    "\n",
    "#Exclude COCO heads\n",
    "model.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "#model.load_weights(weights_path, by_name=True)\n",
    "print(\"Model name: {}\".format(config.NAME))\n",
    "\n",
    "# Set up Datasets Objects \n",
    "dataset_train = Monuseg_dist.MonusegDISTDataset()\n",
    "dataset_val = Monuseg_dist.MonusegDISTDataset()\n",
    "dataset_train.add_class(source = \"Monuseg\", class_id =  1, class_name = \"nucleus\")\n",
    "dataset_val.add_class(source = \"Monuseg\", class_id =  1, class_name = \"nucleus\")\n",
    "\n",
    "# Fill with the samples\n",
    "i = 0\n",
    "for _id in image_ids:\n",
    "    name,_ = os.path.splitext(_id)\n",
    "    if i <= len(image_ids):\n",
    "        dataset_train.add_image(source = \"Monuseg\",\n",
    "                                image_id = name,\n",
    "                                path = os.path.join(image_dir, _id))\n",
    "    i+=1\n",
    "\n",
    "\n",
    "dataset_val.add_image(source = \"Monuseg\",\n",
    "                                image_id = name,\n",
    "                                path = os.path.join(image_dir, _id))\n",
    "    \n",
    "\n",
    "\n",
    "dataset_val.prepare()\n",
    "dataset_train.prepare()\n",
    "\n",
    "print(\"Have {} train images\".format(len(dataset_train.image_ids)))\n",
    "print(\"Have {} val images\".format(len(dataset_val.image_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.0001\n",
      "\n",
      "Checkpoint Path: C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\logs\\monuseg_coco_nonopttrain_disth_tissue20210702T1732\\mask_rcnn_monuseg_coco_nonopttrain_disth_tissue_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "PREPROC                (Conv2D)\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/50\n",
      "60/60 [==============================] - 92s 2s/step - loss: 2.4560 - rpn_class_loss: 0.2824 - rpn_bbox_loss: 0.9614 - mrcnn_class_loss: 0.1587 - mrcnn_bbox_loss: 0.5517 - mrcnn_mask_loss: 0.5017 - val_loss: 2.2956 - val_rpn_class_loss: 0.3587 - val_rpn_bbox_loss: 0.7894 - val_mrcnn_class_loss: 0.3206 - val_mrcnn_bbox_loss: 0.4311 - val_mrcnn_mask_loss: 0.3957\n",
      "Epoch 2/50\n",
      "60/60 [==============================] - 71s 1s/step - loss: 1.9813 - rpn_class_loss: 0.1936 - rpn_bbox_loss: 0.8374 - mrcnn_class_loss: 0.1743 - mrcnn_bbox_loss: 0.4056 - mrcnn_mask_loss: 0.3703 - val_loss: 1.7534 - val_rpn_class_loss: 0.1686 - val_rpn_bbox_loss: 0.7581 - val_mrcnn_class_loss: 0.3165 - val_mrcnn_bbox_loss: 0.2317 - val_mrcnn_mask_loss: 0.2784\n",
      "Epoch 3/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 1.7517 - rpn_class_loss: 0.1586 - rpn_bbox_loss: 0.6624 - mrcnn_class_loss: 0.2517 - mrcnn_bbox_loss: 0.3445 - mrcnn_mask_loss: 0.3345 - val_loss: 1.5778 - val_rpn_class_loss: 0.1632 - val_rpn_bbox_loss: 0.4761 - val_mrcnn_class_loss: 0.3554 - val_mrcnn_bbox_loss: 0.2983 - val_mrcnn_mask_loss: 0.2849\n",
      "Epoch 4/50\n",
      "60/60 [==============================] - 78s 1s/step - loss: 1.6201 - rpn_class_loss: 0.1581 - rpn_bbox_loss: 0.5773 - mrcnn_class_loss: 0.2604 - mrcnn_bbox_loss: 0.3077 - mrcnn_mask_loss: 0.3166 - val_loss: 1.6536 - val_rpn_class_loss: 0.2388 - val_rpn_bbox_loss: 0.4574 - val_mrcnn_class_loss: 0.3841 - val_mrcnn_bbox_loss: 0.2783 - val_mrcnn_mask_loss: 0.2950\n",
      "Epoch 5/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 1.5285 - rpn_class_loss: 0.1393 - rpn_bbox_loss: 0.5282 - mrcnn_class_loss: 0.2660 - mrcnn_bbox_loss: 0.2804 - mrcnn_mask_loss: 0.3146 - val_loss: 1.7154 - val_rpn_class_loss: 0.2981 - val_rpn_bbox_loss: 0.5963 - val_mrcnn_class_loss: 0.3212 - val_mrcnn_bbox_loss: 0.2065 - val_mrcnn_mask_loss: 0.2933\n",
      "Epoch 6/50\n",
      "60/60 [==============================] - 77s 1s/step - loss: 1.3458 - rpn_class_loss: 0.1093 - rpn_bbox_loss: 0.4601 - mrcnn_class_loss: 0.2298 - mrcnn_bbox_loss: 0.2561 - mrcnn_mask_loss: 0.2905 - val_loss: 1.3208 - val_rpn_class_loss: 0.1670 - val_rpn_bbox_loss: 0.4574 - val_mrcnn_class_loss: 0.2363 - val_mrcnn_bbox_loss: 0.1975 - val_mrcnn_mask_loss: 0.2626\n",
      "Epoch 7/50\n",
      "60/60 [==============================] - 81s 1s/step - loss: 1.3673 - rpn_class_loss: 0.1125 - rpn_bbox_loss: 0.4792 - mrcnn_class_loss: 0.2480 - mrcnn_bbox_loss: 0.2466 - mrcnn_mask_loss: 0.2811 - val_loss: 1.4340 - val_rpn_class_loss: 0.0837 - val_rpn_bbox_loss: 0.5479 - val_mrcnn_class_loss: 0.2771 - val_mrcnn_bbox_loss: 0.2393 - val_mrcnn_mask_loss: 0.2859\n",
      "Epoch 8/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 1.2411 - rpn_class_loss: 0.0993 - rpn_bbox_loss: 0.4356 - mrcnn_class_loss: 0.2222 - mrcnn_bbox_loss: 0.2203 - mrcnn_mask_loss: 0.2637 - val_loss: 0.9802 - val_rpn_class_loss: 0.0886 - val_rpn_bbox_loss: 0.2905 - val_mrcnn_class_loss: 0.2226 - val_mrcnn_bbox_loss: 0.1392 - val_mrcnn_mask_loss: 0.2393\n",
      "Epoch 9/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 1.2357 - rpn_class_loss: 0.0894 - rpn_bbox_loss: 0.4275 - mrcnn_class_loss: 0.2224 - mrcnn_bbox_loss: 0.2231 - mrcnn_mask_loss: 0.2733 - val_loss: 1.0057 - val_rpn_class_loss: 0.0711 - val_rpn_bbox_loss: 0.2793 - val_mrcnn_class_loss: 0.2062 - val_mrcnn_bbox_loss: 0.1793 - val_mrcnn_mask_loss: 0.2698\n",
      "Epoch 10/50\n",
      "60/60 [==============================] - 82s 1s/step - loss: 1.2639 - rpn_class_loss: 0.0998 - rpn_bbox_loss: 0.4492 - mrcnn_class_loss: 0.2161 - mrcnn_bbox_loss: 0.2277 - mrcnn_mask_loss: 0.2712 - val_loss: 1.2489 - val_rpn_class_loss: 0.2068 - val_rpn_bbox_loss: 0.3763 - val_mrcnn_class_loss: 0.2351 - val_mrcnn_bbox_loss: 0.1808 - val_mrcnn_mask_loss: 0.2499\n",
      "Epoch 11/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 1.2095 - rpn_class_loss: 0.0928 - rpn_bbox_loss: 0.4200 - mrcnn_class_loss: 0.2172 - mrcnn_bbox_loss: 0.2258 - mrcnn_mask_loss: 0.2538 - val_loss: 1.3269 - val_rpn_class_loss: 0.1067 - val_rpn_bbox_loss: 0.4121 - val_mrcnn_class_loss: 0.3180 - val_mrcnn_bbox_loss: 0.2583 - val_mrcnn_mask_loss: 0.2318\n",
      "Epoch 12/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 1.1725 - rpn_class_loss: 0.0922 - rpn_bbox_loss: 0.4218 - mrcnn_class_loss: 0.1989 - mrcnn_bbox_loss: 0.2077 - mrcnn_mask_loss: 0.2519 - val_loss: 1.0940 - val_rpn_class_loss: 0.0732 - val_rpn_bbox_loss: 0.3103 - val_mrcnn_class_loss: 0.2604 - val_mrcnn_bbox_loss: 0.1976 - val_mrcnn_mask_loss: 0.2525\n",
      "Epoch 13/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 1.2228 - rpn_class_loss: 0.0892 - rpn_bbox_loss: 0.4403 - mrcnn_class_loss: 0.2125 - mrcnn_bbox_loss: 0.2182 - mrcnn_mask_loss: 0.2625 - val_loss: 0.9800 - val_rpn_class_loss: 0.0908 - val_rpn_bbox_loss: 0.3304 - val_mrcnn_class_loss: 0.1964 - val_mrcnn_bbox_loss: 0.1416 - val_mrcnn_mask_loss: 0.2207\n",
      "Epoch 14/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 1.1820 - rpn_class_loss: 0.0879 - rpn_bbox_loss: 0.4029 - mrcnn_class_loss: 0.2258 - mrcnn_bbox_loss: 0.2104 - mrcnn_mask_loss: 0.2549 - val_loss: 1.3952 - val_rpn_class_loss: 0.1134 - val_rpn_bbox_loss: 0.3794 - val_mrcnn_class_loss: 0.3479 - val_mrcnn_bbox_loss: 0.2846 - val_mrcnn_mask_loss: 0.2699\n",
      "Epoch 15/50\n",
      "60/60 [==============================] - 81s 1s/step - loss: 1.1353 - rpn_class_loss: 0.0783 - rpn_bbox_loss: 0.3813 - mrcnn_class_loss: 0.2184 - mrcnn_bbox_loss: 0.2052 - mrcnn_mask_loss: 0.2520 - val_loss: 1.0186 - val_rpn_class_loss: 0.1288 - val_rpn_bbox_loss: 0.3212 - val_mrcnn_class_loss: 0.2129 - val_mrcnn_bbox_loss: 0.1381 - val_mrcnn_mask_loss: 0.2175\n",
      "Epoch 16/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 1.0169 - rpn_class_loss: 0.0654 - rpn_bbox_loss: 0.3477 - mrcnn_class_loss: 0.1942 - mrcnn_bbox_loss: 0.1829 - mrcnn_mask_loss: 0.2267 - val_loss: 0.9433 - val_rpn_class_loss: 0.0888 - val_rpn_bbox_loss: 0.2560 - val_mrcnn_class_loss: 0.1983 - val_mrcnn_bbox_loss: 0.1803 - val_mrcnn_mask_loss: 0.2199\n",
      "Epoch 17/50\n",
      "60/60 [==============================] - 78s 1s/step - loss: 1.0821 - rpn_class_loss: 0.0719 - rpn_bbox_loss: 0.3672 - mrcnn_class_loss: 0.2055 - mrcnn_bbox_loss: 0.1960 - mrcnn_mask_loss: 0.2416 - val_loss: 1.1327 - val_rpn_class_loss: 0.0616 - val_rpn_bbox_loss: 0.4913 - val_mrcnn_class_loss: 0.2142 - val_mrcnn_bbox_loss: 0.1524 - val_mrcnn_mask_loss: 0.2131\n",
      "Epoch 18/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 1.0730 - rpn_class_loss: 0.0869 - rpn_bbox_loss: 0.3836 - mrcnn_class_loss: 0.1939 - mrcnn_bbox_loss: 0.1834 - mrcnn_mask_loss: 0.2253 - val_loss: 1.0185 - val_rpn_class_loss: 0.1115 - val_rpn_bbox_loss: 0.2635 - val_mrcnn_class_loss: 0.2738 - val_mrcnn_bbox_loss: 0.1529 - val_mrcnn_mask_loss: 0.2168\n",
      "Epoch 19/50\n",
      "60/60 [==============================] - 77s 1s/step - loss: 1.0408 - rpn_class_loss: 0.0813 - rpn_bbox_loss: 0.3420 - mrcnn_class_loss: 0.2079 - mrcnn_bbox_loss: 0.1831 - mrcnn_mask_loss: 0.2266 - val_loss: 0.9314 - val_rpn_class_loss: 0.0856 - val_rpn_bbox_loss: 0.3326 - val_mrcnn_class_loss: 0.2142 - val_mrcnn_bbox_loss: 0.1126 - val_mrcnn_mask_loss: 0.1865\n",
      "Epoch 20/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 1.0724 - rpn_class_loss: 0.0774 - rpn_bbox_loss: 0.3746 - mrcnn_class_loss: 0.2084 - mrcnn_bbox_loss: 0.1792 - mrcnn_mask_loss: 0.2327 - val_loss: 0.8054 - val_rpn_class_loss: 0.0790 - val_rpn_bbox_loss: 0.2157 - val_mrcnn_class_loss: 0.1953 - val_mrcnn_bbox_loss: 0.1260 - val_mrcnn_mask_loss: 0.1893\n",
      "Epoch 21/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 1.0201 - rpn_class_loss: 0.0643 - rpn_bbox_loss: 0.3413 - mrcnn_class_loss: 0.1925 - mrcnn_bbox_loss: 0.1912 - mrcnn_mask_loss: 0.2308 - val_loss: 0.9750 - val_rpn_class_loss: 0.0978 - val_rpn_bbox_loss: 0.2616 - val_mrcnn_class_loss: 0.2446 - val_mrcnn_bbox_loss: 0.1442 - val_mrcnn_mask_loss: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 1.0070 - rpn_class_loss: 0.0669 - rpn_bbox_loss: 0.3542 - mrcnn_class_loss: 0.1936 - mrcnn_bbox_loss: 0.1792 - mrcnn_mask_loss: 0.2130 - val_loss: 0.9827 - val_rpn_class_loss: 0.1370 - val_rpn_bbox_loss: 0.3056 - val_mrcnn_class_loss: 0.1978 - val_mrcnn_bbox_loss: 0.1473 - val_mrcnn_mask_loss: 0.1949\n",
      "Epoch 23/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 1.0269 - rpn_class_loss: 0.0698 - rpn_bbox_loss: 0.3555 - mrcnn_class_loss: 0.1963 - mrcnn_bbox_loss: 0.1842 - mrcnn_mask_loss: 0.2211 - val_loss: 0.8165 - val_rpn_class_loss: 0.0863 - val_rpn_bbox_loss: 0.2170 - val_mrcnn_class_loss: 0.1824 - val_mrcnn_bbox_loss: 0.1284 - val_mrcnn_mask_loss: 0.2024\n",
      "Epoch 24/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 0.9253 - rpn_class_loss: 0.0644 - rpn_bbox_loss: 0.2934 - mrcnn_class_loss: 0.1916 - mrcnn_bbox_loss: 0.1631 - mrcnn_mask_loss: 0.2129 - val_loss: 0.6969 - val_rpn_class_loss: 0.0481 - val_rpn_bbox_loss: 0.1763 - val_mrcnn_class_loss: 0.1725 - val_mrcnn_bbox_loss: 0.1174 - val_mrcnn_mask_loss: 0.1825\n",
      "Epoch 25/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 0.9624 - rpn_class_loss: 0.0678 - rpn_bbox_loss: 0.3282 - mrcnn_class_loss: 0.1812 - mrcnn_bbox_loss: 0.1739 - mrcnn_mask_loss: 0.2113 - val_loss: 0.9540 - val_rpn_class_loss: 0.0682 - val_rpn_bbox_loss: 0.2740 - val_mrcnn_class_loss: 0.2563 - val_mrcnn_bbox_loss: 0.1729 - val_mrcnn_mask_loss: 0.1826\n",
      "Epoch 26/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 1.0899 - rpn_class_loss: 0.0798 - rpn_bbox_loss: 0.3649 - mrcnn_class_loss: 0.2072 - mrcnn_bbox_loss: 0.2013 - mrcnn_mask_loss: 0.2366 - val_loss: 0.8835 - val_rpn_class_loss: 0.0607 - val_rpn_bbox_loss: 0.2633 - val_mrcnn_class_loss: 0.2174 - val_mrcnn_bbox_loss: 0.1501 - val_mrcnn_mask_loss: 0.1920\n",
      "Epoch 27/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 0.9144 - rpn_class_loss: 0.0607 - rpn_bbox_loss: 0.3105 - mrcnn_class_loss: 0.1599 - mrcnn_bbox_loss: 0.1679 - mrcnn_mask_loss: 0.2154 - val_loss: 0.7953 - val_rpn_class_loss: 0.0791 - val_rpn_bbox_loss: 0.2455 - val_mrcnn_class_loss: 0.2025 - val_mrcnn_bbox_loss: 0.1036 - val_mrcnn_mask_loss: 0.1645\n",
      "Epoch 28/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 0.9464 - rpn_class_loss: 0.0655 - rpn_bbox_loss: 0.3061 - mrcnn_class_loss: 0.1881 - mrcnn_bbox_loss: 0.1719 - mrcnn_mask_loss: 0.2148 - val_loss: 0.6895 - val_rpn_class_loss: 0.0593 - val_rpn_bbox_loss: 0.1745 - val_mrcnn_class_loss: 0.1831 - val_mrcnn_bbox_loss: 0.1013 - val_mrcnn_mask_loss: 0.1713\n",
      "Epoch 29/50\n",
      "60/60 [==============================] - 77s 1s/step - loss: 0.9676 - rpn_class_loss: 0.0630 - rpn_bbox_loss: 0.3370 - mrcnn_class_loss: 0.1813 - mrcnn_bbox_loss: 0.1746 - mrcnn_mask_loss: 0.2117 - val_loss: 1.0925 - val_rpn_class_loss: 0.1436 - val_rpn_bbox_loss: 0.3641 - val_mrcnn_class_loss: 0.2355 - val_mrcnn_bbox_loss: 0.1393 - val_mrcnn_mask_loss: 0.2100\n",
      "Epoch 30/50\n",
      "60/60 [==============================] - 78s 1s/step - loss: 0.9220 - rpn_class_loss: 0.0591 - rpn_bbox_loss: 0.3019 - mrcnn_class_loss: 0.1714 - mrcnn_bbox_loss: 0.1735 - mrcnn_mask_loss: 0.2161 - val_loss: 0.6572 - val_rpn_class_loss: 0.0479 - val_rpn_bbox_loss: 0.1525 - val_mrcnn_class_loss: 0.1571 - val_mrcnn_bbox_loss: 0.1158 - val_mrcnn_mask_loss: 0.1839\n",
      "Epoch 31/50\n",
      "60/60 [==============================] - 78s 1s/step - loss: 0.8626 - rpn_class_loss: 0.0566 - rpn_bbox_loss: 0.2882 - mrcnn_class_loss: 0.1639 - mrcnn_bbox_loss: 0.1620 - mrcnn_mask_loss: 0.1919 - val_loss: 0.7763 - val_rpn_class_loss: 0.0820 - val_rpn_bbox_loss: 0.1974 - val_mrcnn_class_loss: 0.1982 - val_mrcnn_bbox_loss: 0.1086 - val_mrcnn_mask_loss: 0.1900\n",
      "Epoch 32/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 0.9521 - rpn_class_loss: 0.0598 - rpn_bbox_loss: 0.3154 - mrcnn_class_loss: 0.1902 - mrcnn_bbox_loss: 0.1744 - mrcnn_mask_loss: 0.2123 - val_loss: 0.8267 - val_rpn_class_loss: 0.0261 - val_rpn_bbox_loss: 0.2002 - val_mrcnn_class_loss: 0.2350 - val_mrcnn_bbox_loss: 0.1595 - val_mrcnn_mask_loss: 0.2059\n",
      "Epoch 33/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 0.9303 - rpn_class_loss: 0.0585 - rpn_bbox_loss: 0.3024 - mrcnn_class_loss: 0.1902 - mrcnn_bbox_loss: 0.1786 - mrcnn_mask_loss: 0.2005 - val_loss: 0.8046 - val_rpn_class_loss: 0.0561 - val_rpn_bbox_loss: 0.1991 - val_mrcnn_class_loss: 0.2631 - val_mrcnn_bbox_loss: 0.1114 - val_mrcnn_mask_loss: 0.1749\n",
      "Epoch 34/50\n",
      "60/60 [==============================] - 81s 1s/step - loss: 0.9946 - rpn_class_loss: 0.0637 - rpn_bbox_loss: 0.3481 - mrcnn_class_loss: 0.1901 - mrcnn_bbox_loss: 0.1812 - mrcnn_mask_loss: 0.2115 - val_loss: 1.0146 - val_rpn_class_loss: 0.0548 - val_rpn_bbox_loss: 0.3901 - val_mrcnn_class_loss: 0.2859 - val_mrcnn_bbox_loss: 0.1088 - val_mrcnn_mask_loss: 0.1748\n",
      "Epoch 35/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 0.9442 - rpn_class_loss: 0.0577 - rpn_bbox_loss: 0.3009 - mrcnn_class_loss: 0.1912 - mrcnn_bbox_loss: 0.1805 - mrcnn_mask_loss: 0.2139 - val_loss: 0.7618 - val_rpn_class_loss: 0.0653 - val_rpn_bbox_loss: 0.1853 - val_mrcnn_class_loss: 0.2064 - val_mrcnn_bbox_loss: 0.1119 - val_mrcnn_mask_loss: 0.1930\n",
      "Epoch 36/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 0.9903 - rpn_class_loss: 0.0680 - rpn_bbox_loss: 0.3595 - mrcnn_class_loss: 0.1911 - mrcnn_bbox_loss: 0.1740 - mrcnn_mask_loss: 0.1977 - val_loss: 0.7784 - val_rpn_class_loss: 0.0547 - val_rpn_bbox_loss: 0.2007 - val_mrcnn_class_loss: 0.2448 - val_mrcnn_bbox_loss: 0.1149 - val_mrcnn_mask_loss: 0.1632\n",
      "Epoch 37/50\n",
      "60/60 [==============================] - 78s 1s/step - loss: 0.9479 - rpn_class_loss: 0.0604 - rpn_bbox_loss: 0.3633 - mrcnn_class_loss: 0.1595 - mrcnn_bbox_loss: 0.1684 - mrcnn_mask_loss: 0.1961 - val_loss: 0.7362 - val_rpn_class_loss: 0.0575 - val_rpn_bbox_loss: 0.2066 - val_mrcnn_class_loss: 0.1920 - val_mrcnn_bbox_loss: 0.1064 - val_mrcnn_mask_loss: 0.1737\n",
      "Epoch 38/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 0.8807 - rpn_class_loss: 0.0612 - rpn_bbox_loss: 0.3162 - mrcnn_class_loss: 0.1616 - mrcnn_bbox_loss: 0.1498 - mrcnn_mask_loss: 0.1919 - val_loss: 0.7927 - val_rpn_class_loss: 0.0782 - val_rpn_bbox_loss: 0.2727 - val_mrcnn_class_loss: 0.1915 - val_mrcnn_bbox_loss: 0.0746 - val_mrcnn_mask_loss: 0.1756\n",
      "Epoch 39/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 0.9522 - rpn_class_loss: 0.0636 - rpn_bbox_loss: 0.3140 - mrcnn_class_loss: 0.1889 - mrcnn_bbox_loss: 0.1817 - mrcnn_mask_loss: 0.2040 - val_loss: 0.6868 - val_rpn_class_loss: 0.0245 - val_rpn_bbox_loss: 0.1783 - val_mrcnn_class_loss: 0.1997 - val_mrcnn_bbox_loss: 0.1069 - val_mrcnn_mask_loss: 0.1774\n",
      "Epoch 40/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 0.9298 - rpn_class_loss: 0.0616 - rpn_bbox_loss: 0.3317 - mrcnn_class_loss: 0.1726 - mrcnn_bbox_loss: 0.1613 - mrcnn_mask_loss: 0.2025 - val_loss: 0.7719 - val_rpn_class_loss: 0.0500 - val_rpn_bbox_loss: 0.2307 - val_mrcnn_class_loss: 0.2123 - val_mrcnn_bbox_loss: 0.1007 - val_mrcnn_mask_loss: 0.1782\n",
      "Epoch 41/50\n",
      "60/60 [==============================] - 81s 1s/step - loss: 0.8973 - rpn_class_loss: 0.0576 - rpn_bbox_loss: 0.3075 - mrcnn_class_loss: 0.1758 - mrcnn_bbox_loss: 0.1607 - mrcnn_mask_loss: 0.1958 - val_loss: 1.0765 - val_rpn_class_loss: 0.1434 - val_rpn_bbox_loss: 0.3872 - val_mrcnn_class_loss: 0.1954 - val_mrcnn_bbox_loss: 0.1457 - val_mrcnn_mask_loss: 0.2049\n",
      "Epoch 42/50\n",
      "60/60 [==============================] - 79s 1s/step - loss: 0.8322 - rpn_class_loss: 0.0563 - rpn_bbox_loss: 0.2820 - mrcnn_class_loss: 0.1644 - mrcnn_bbox_loss: 0.1452 - mrcnn_mask_loss: 0.1843 - val_loss: 0.7091 - val_rpn_class_loss: 0.0539 - val_rpn_bbox_loss: 0.1736 - val_mrcnn_class_loss: 0.2119 - val_mrcnn_bbox_loss: 0.0996 - val_mrcnn_mask_loss: 0.1702\n",
      "Epoch 43/50\n",
      "60/60 [==============================] - 77s 1s/step - loss: 0.8592 - rpn_class_loss: 0.0585 - rpn_bbox_loss: 0.2943 - mrcnn_class_loss: 0.1510 - mrcnn_bbox_loss: 0.1656 - mrcnn_mask_loss: 0.1897 - val_loss: 0.9305 - val_rpn_class_loss: 0.0572 - val_rpn_bbox_loss: 0.2873 - val_mrcnn_class_loss: 0.2021 - val_mrcnn_bbox_loss: 0.1649 - val_mrcnn_mask_loss: 0.2190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50\n",
      "60/60 [==============================] - 81s 1s/step - loss: 0.8979 - rpn_class_loss: 0.0548 - rpn_bbox_loss: 0.2947 - mrcnn_class_loss: 0.1672 - mrcnn_bbox_loss: 0.1765 - mrcnn_mask_loss: 0.2047 - val_loss: 0.7448 - val_rpn_class_loss: 0.0567 - val_rpn_bbox_loss: 0.1600 - val_mrcnn_class_loss: 0.2279 - val_mrcnn_bbox_loss: 0.1172 - val_mrcnn_mask_loss: 0.1830\n",
      "Epoch 45/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 0.8209 - rpn_class_loss: 0.0489 - rpn_bbox_loss: 0.2741 - mrcnn_class_loss: 0.1643 - mrcnn_bbox_loss: 0.1540 - mrcnn_mask_loss: 0.1796 - val_loss: 0.9862 - val_rpn_class_loss: 0.1107 - val_rpn_bbox_loss: 0.4629 - val_mrcnn_class_loss: 0.1839 - val_mrcnn_bbox_loss: 0.0865 - val_mrcnn_mask_loss: 0.1422\n",
      "Epoch 46/50\n",
      "60/60 [==============================] - 78s 1s/step - loss: 0.8255 - rpn_class_loss: 0.0450 - rpn_bbox_loss: 0.2738 - mrcnn_class_loss: 0.1716 - mrcnn_bbox_loss: 0.1569 - mrcnn_mask_loss: 0.1782 - val_loss: 0.9765 - val_rpn_class_loss: 0.0944 - val_rpn_bbox_loss: 0.3037 - val_mrcnn_class_loss: 0.2327 - val_mrcnn_bbox_loss: 0.1224 - val_mrcnn_mask_loss: 0.2232\n",
      "Epoch 47/50\n",
      "60/60 [==============================] - 77s 1s/step - loss: 0.8174 - rpn_class_loss: 0.0528 - rpn_bbox_loss: 0.2552 - mrcnn_class_loss: 0.1572 - mrcnn_bbox_loss: 0.1563 - mrcnn_mask_loss: 0.1958 - val_loss: 0.7140 - val_rpn_class_loss: 0.0608 - val_rpn_bbox_loss: 0.2396 - val_mrcnn_class_loss: 0.1542 - val_mrcnn_bbox_loss: 0.0878 - val_mrcnn_mask_loss: 0.1716\n",
      "Epoch 48/50\n",
      "60/60 [==============================] - 78s 1s/step - loss: 0.8413 - rpn_class_loss: 0.0531 - rpn_bbox_loss: 0.2827 - mrcnn_class_loss: 0.1525 - mrcnn_bbox_loss: 0.1570 - mrcnn_mask_loss: 0.1959 - val_loss: 0.8991 - val_rpn_class_loss: 0.0856 - val_rpn_bbox_loss: 0.2639 - val_mrcnn_class_loss: 0.2287 - val_mrcnn_bbox_loss: 0.1273 - val_mrcnn_mask_loss: 0.1936\n",
      "Epoch 49/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 0.8248 - rpn_class_loss: 0.0531 - rpn_bbox_loss: 0.2769 - mrcnn_class_loss: 0.1452 - mrcnn_bbox_loss: 0.1585 - mrcnn_mask_loss: 0.1909 - val_loss: 0.7472 - val_rpn_class_loss: 0.0823 - val_rpn_bbox_loss: 0.2337 - val_mrcnn_class_loss: 0.1677 - val_mrcnn_bbox_loss: 0.1013 - val_mrcnn_mask_loss: 0.1622\n",
      "Epoch 50/50\n",
      "60/60 [==============================] - 76s 1s/step - loss: 0.8388 - rpn_class_loss: 0.0527 - rpn_bbox_loss: 0.2837 - mrcnn_class_loss: 0.1498 - mrcnn_bbox_loss: 0.1592 - mrcnn_mask_loss: 0.1933 - val_loss: 0.6617 - val_rpn_class_loss: 0.0571 - val_rpn_bbox_loss: 0.2073 - val_mrcnn_class_loss: 0.1792 - val_mrcnn_bbox_loss: 0.0707 - val_mrcnn_mask_loss: 0.1473\n"
     ]
    }
   ],
   "source": [
    "# Regular training\n",
    "model.train(dataset_train, dataset_val,\n",
    "       learning_rate=config.LEARNING_RATE,\n",
    "        epochs=50,\n",
    "        augmentation=augmentation,\n",
    "        layers='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.0002\n",
      "\n",
      "Checkpoint Path: C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\logs\\monuseg_coco_nonopttrain_disth_tissue20210702T1854\\mask_rcnn_monuseg_coco_nonopttrain_disth_tissue_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "PREPROC                (Conv2D)\n",
      "conv1                  (Conv2D)\n",
      "In model:  rpn_model\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node PREPROC_1/convolution}}]]\n\t [[mul_67/_5305]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node PREPROC_1/convolution}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6151bfbd2b6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0maugmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         layers=r\"(PREPROC.*)|(conv1.*)|(mrcnn\\_.*)\")\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m model.train(dataset_train, dataset_val,\n",
      "\u001b[1;32m~\\GitHub\\Mask_RCNN_Thesis\\mrcnn\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources, use_randaugment)\u001b[0m\n\u001b[0;32m   2913\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2914\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2915\u001b[1;33m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2916\u001b[0m         )\n\u001b[0;32m   2917\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1658\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node PREPROC_1/convolution}}]]\n\t [[mul_67/_5305]]\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node PREPROC_1/convolution}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "# Optimal stage-based training\n",
    "model.train(dataset_train, dataset_val,\n",
    "       learning_rate=config.LEARNING_RATE*2,\n",
    "        epochs=5,\n",
    "        augmentation=augmentation,\n",
    "        layers=r\"(PREPROC.*)|(conv1.*)|(mrcnn\\_.*)\")\n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "       learning_rate=config.LEARNING_RATE,\n",
    "        epochs=5+35,\n",
    "        augmentation=augmentation,\n",
    "        layers=\"all\")\n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "       learning_rate=config.LEARNING_RATE * 0.5,\n",
    "        epochs=40+5,\n",
    "        augmentation=augmentation,\n",
    "        layers='5+')\n",
    "\n",
    "model.train(dataset_train, dataset_val,\n",
    "       learning_rate=config.LEARNING_RATE * 0.1,\n",
    "        epochs=45+5,\n",
    "        augmentation=augmentation,\n",
    "        layers='heads')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\datasets\\MoNuSeg_Dist\\train\\tissue_images\n",
      "TCGA-18-5592-01Z-00-DX1\n",
      "TCGA-21-5784-01Z-00-DX1\n",
      "TCGA-21-5786-01Z-00-DX1\n",
      "TCGA-38-6178-01Z-00-DX1\n",
      "TCGA-49-4488-01Z-00-DX1\n",
      "TCGA-50-5931-01Z-00-DX1\n",
      "TCGA-A7-A13E-01Z-00-DX1\n",
      "TCGA-A7-A13F-01Z-00-DX1\n",
      "TCGA-AR-A1AK-01Z-00-DX1\n",
      "TCGA-AR-A1AS-01Z-00-DX1\n",
      "TCGA-AY-A8YK-01A-01-TS1\n",
      "TCGA-B0-5698-01Z-00-DX1\n",
      "TCGA-B0-5710-01Z-00-DX1\n",
      "TCGA-B0-5711-01Z-00-DX1\n",
      "TCGA-CH-5767-01Z-00-DX1\n",
      "TCGA-DK-A2I6-01A-01-TS1\n",
      "TCGA-E2-A14V-01Z-00-DX1\n",
      "TCGA-E2-A1B5-01Z-00-DX1\n",
      "TCGA-G2-A2EK-01A-02-TSB\n",
      "TCGA-G9-6336-01Z-00-DX1\n",
      "TCGA-G9-6348-01Z-00-DX1\n",
      "TCGA-G9-6356-01Z-00-DX1\n",
      "TCGA-G9-6362-01Z-00-DX1\n",
      "TCGA-G9-6363-01Z-00-DX1\n",
      "TCGA-HE-7128-01Z-00-DX1\n",
      "TCGA-HE-7129-01Z-00-DX1\n",
      "TCGA-HE-7130-01Z-00-DX1\n",
      "TCGA-KB-A93J-01A-01-TS1\n",
      "TCGA-NH-A8F7-01A-01-TS1\n",
      "TCGA-RD-A8N9-01A-01-TS1\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = MONUSEG_DIR\n",
    "subset = \"train\"\n",
    "dataset_dir = os.path.join(dataset_dir, subset)\n",
    "    \n",
    "dict_names = {}\n",
    "\n",
    "image_dir = os.path.join(dataset_dir, \"tissue_images\")\n",
    "image_ids = os.listdir(image_dir)\n",
    "# Fill with the samples\n",
    "for _id in image_ids:\n",
    "    name,_ = os.path.splitext(_id)\n",
    "    dict_names[name] = os.path.join(image_dir, _id)\n",
    "\n",
    "print(image_dir)\n",
    "for k in dict_names.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n",
      "24\n",
      "24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# Mixture = 2x Bladder, Colon, Stomach\n",
    "# 1: Kidney, Mixture, Liver, Prostate (No Breast)\n",
    "# 2: Mixture, Liver, Prostate, Breast (No Kidney)\n",
    "# 3: Liver, Prostate, Breast, Kidney (No Mixture)\n",
    "# 4: Prostate, Breast, Kidney, Mixture (No Liver)\n",
    "# 5: Breast, Kidney, Mixture, Liver (No Prostate) \n",
    "\n",
    "organ_dict = {\n",
    "\"Breast\":[\"TCGA-A7-A13E-01Z-00-DX1\",\n",
    "    \"TCGA-A7-A13F-01Z-00-DX1\",\n",
    "    \"TCGA-AR-A1AK-01Z-00-DX1\",\n",
    "    \"TCGA-AR-A1AS-01Z-00-DX1\",\n",
    "    \"TCGA-E2-A14V-01Z-00-DX1\",\n",
    "    \"TCGA-E2-A1B5-01Z-00-DX1\"],\n",
    "\"Kidney\":[\"TCGA-B0-5698-01Z-00-DX1\",\n",
    "    \"TCGA-B0-5710-01Z-00-DX1\",\n",
    "    \"TCGA-B0-5711-01Z-00-DX1\",\n",
    "    \"TCGA-HE-7128-01Z-00-DX1\",\n",
    "    \"TCGA-HE-7129-01Z-00-DX1\",\n",
    "    \"TCGA-HE-7130-01Z-00-DX1\"],\n",
    "\"Liver\":[\"TCGA-18-5592-01Z-00-DX1\",\n",
    "    \"TCGA-21-5784-01Z-00-DX1\",\n",
    "    \"TCGA-21-5786-01Z-00-DX1\",\n",
    "    \"TCGA-38-6178-01Z-00-DX1\",\n",
    "    \"TCGA-49-4488-01Z-00-DX1\",\n",
    "    \"TCGA-50-5931-01Z-00-DX1\"],\n",
    "\"Prostate\":[\"TCGA-CH-5767-01Z-00-DX1\",\n",
    "    \"TCGA-G9-6336-01Z-00-DX1\",\n",
    "    \"TCGA-G9-6348-01Z-00-DX1\",\n",
    "    \"TCGA-G9-6356-01Z-00-DX1\",\n",
    "    \"TCGA-G9-6362-01Z-00-DX1\",\n",
    "    \"TCGA-G9-6363-01Z-00-DX1\"],\n",
    "\"Mixture\":[\"TCGA-KB-A93J-01A-01-TS1\",\n",
    "    \"TCGA-RD-A8N9-01A-01-TS1\",\n",
    "    \"TCGA-AY-A8YK-01A-01-TS1\",\n",
    "    \"TCGA-NH-A8F7-01A-01-TS1\",\n",
    "    \"TCGA-DK-A2I6-01A-01-TS1\",\n",
    "    \"TCGA-G2-A2EK-01A-02-TSB\"]\n",
    "}\n",
    "\n",
    "fold1 = []\n",
    "for k in [\"Kidney\", \"Liver\", \"Prostate\", \"Mixture\"]:\n",
    "    fold1.extend(organ_dict[k])\n",
    "\n",
    "fold2 = []\n",
    "for k in [\"Mixture\", \"Liver\", \"Prostate\", \"Breast\"]:\n",
    "    fold2.extend(organ_dict[k])\n",
    "\n",
    "fold3 = []\n",
    "for k in [\"Liver\", \"Prostate\", \"Breast\", \"Kidney\"]:\n",
    "    fold3.extend(organ_dict[k])\n",
    "    \n",
    "fold4 = []\n",
    "for k in [\"Prostate\", \"Breast\", \"Kidney\", \"Mixture\"]:\n",
    "    fold4.extend(organ_dict[k])\n",
    "    \n",
    "fold5 = []\n",
    "for k in [\"Breast\", \"Kidney\", \"Mixture\", \"Liver\"]:\n",
    "    fold5.extend(organ_dict[k])\n",
    "    \n",
    "       \n",
    "fold_list = [fold1, fold2, fold3, fold4, fold5]\n",
    "for f in fold_list:\n",
    "    print(len(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Nr. 2 Fold:\n",
      "['TCGA-18-5592-01Z-00-DX1', 'TCGA-21-5784-01Z-00-DX1', 'TCGA-21-5786-01Z-00-DX1', 'TCGA-38-6178-01Z-00-DX1', 'TCGA-49-4488-01Z-00-DX1', 'TCGA-50-5931-01Z-00-DX1', 'TCGA-CH-5767-01Z-00-DX1', 'TCGA-G9-6336-01Z-00-DX1', 'TCGA-G9-6348-01Z-00-DX1', 'TCGA-G9-6356-01Z-00-DX1', 'TCGA-G9-6362-01Z-00-DX1', 'TCGA-G9-6363-01Z-00-DX1', 'TCGA-A7-A13E-01Z-00-DX1', 'TCGA-A7-A13F-01Z-00-DX1', 'TCGA-AR-A1AK-01Z-00-DX1', 'TCGA-AR-A1AS-01Z-00-DX1', 'TCGA-E2-A14V-01Z-00-DX1', 'TCGA-E2-A1B5-01Z-00-DX1', 'TCGA-B0-5698-01Z-00-DX1', 'TCGA-B0-5710-01Z-00-DX1', 'TCGA-B0-5711-01Z-00-DX1', 'TCGA-HE-7128-01Z-00-DX1', 'TCGA-HE-7129-01Z-00-DX1', 'TCGA-HE-7130-01Z-00-DX1']\n",
      "Loding model from: C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\mask_rcnn_coco.h5\n",
      "\n",
      "Starting at epoch 0. LR=0.0002\n",
      "\n",
      "Checkpoint Path: C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\logs\\monuseg_5fold_coco_dist_h_tissue_img220210703T1151\\mask_rcnn_monuseg_5fold_coco_dist_h_tissue_img2_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "PREPROC                (Conv2D)\n",
      "conv1                  (Conv2D)\n",
      "In model:  rpn_model\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\tensorlflow1.14\\lib\\site-packages\\keras\\callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/5\n",
      "60/60 [==============================] - 89s 1s/step - loss: 3.2722 - rpn_class_loss: 0.7931 - rpn_bbox_loss: 1.1649 - mrcnn_class_loss: 0.0959 - mrcnn_bbox_loss: 0.6644 - mrcnn_mask_loss: 0.5539\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\keras\\callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 72s 1s/step - loss: 2.8297 - rpn_class_loss: 0.6888 - rpn_bbox_loss: 1.1042 - mrcnn_class_loss: 0.0443 - mrcnn_bbox_loss: 0.5122 - mrcnn_mask_loss: 0.4800\n",
      "Epoch 3/5\n",
      "60/60 [==============================] - 82s 1s/step - loss: 2.6182 - rpn_class_loss: 0.6905 - rpn_bbox_loss: 1.0782 - mrcnn_class_loss: 0.0341 - mrcnn_bbox_loss: 0.4248 - mrcnn_mask_loss: 0.3906\n",
      "Epoch 4/5\n",
      "60/60 [==============================] - 79s 1s/step - loss: 2.5778 - rpn_class_loss: 0.6781 - rpn_bbox_loss: 1.0646 - mrcnn_class_loss: 0.0299 - mrcnn_bbox_loss: 0.4331 - mrcnn_mask_loss: 0.3721\n",
      "Epoch 5/5\n",
      "60/60 [==============================] - 81s 1s/step - loss: 2.4940 - rpn_class_loss: 0.6535 - rpn_bbox_loss: 1.0680 - mrcnn_class_loss: 0.0300 - mrcnn_bbox_loss: 0.3953 - mrcnn_mask_loss: 0.3472\n",
      "\n",
      "Starting at epoch 5. LR=0.0001\n",
      "\n",
      "Checkpoint Path: C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\logs\\monuseg_5fold_coco_dist_h_tissue_img220210703T1151\\mask_rcnn_monuseg_5fold_coco_dist_h_tissue_img2_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "PREPROC                (Conv2D)\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "60/60 [==============================] - 85s 1s/step - loss: 1.9803 - rpn_class_loss: 0.2769 - rpn_bbox_loss: 0.8867 - mrcnn_class_loss: 0.1269 - mrcnn_bbox_loss: 0.3643 - mrcnn_mask_loss: 0.3254\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\keras\\callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 76s 1s/step - loss: 1.5866 - rpn_class_loss: 0.1354 - rpn_bbox_loss: 0.7107 - mrcnn_class_loss: 0.2200 - mrcnn_bbox_loss: 0.2629 - mrcnn_mask_loss: 0.2576\n",
      "Epoch 8/20\n",
      "60/60 [==============================] - 77s 1s/step - loss: 1.3026 - rpn_class_loss: 0.0968 - rpn_bbox_loss: 0.5114 - mrcnn_class_loss: 0.2413 - mrcnn_bbox_loss: 0.2165 - mrcnn_mask_loss: 0.2365\n",
      "Epoch 9/20\n",
      "60/60 [==============================] - 82s 1s/step - loss: 1.1947 - rpn_class_loss: 0.0862 - rpn_bbox_loss: 0.4492 - mrcnn_class_loss: 0.2328 - mrcnn_bbox_loss: 0.1986 - mrcnn_mask_loss: 0.2278\n",
      "Epoch 10/20\n",
      "60/60 [==============================] - 85s 1s/step - loss: 1.0470 - rpn_class_loss: 0.0822 - rpn_bbox_loss: 0.3840 - mrcnn_class_loss: 0.2003 - mrcnn_bbox_loss: 0.1705 - mrcnn_mask_loss: 0.2099\n",
      "Epoch 11/20\n",
      "60/60 [==============================] - 76s 1s/step - loss: 1.0495 - rpn_class_loss: 0.0734 - rpn_bbox_loss: 0.3866 - mrcnn_class_loss: 0.2088 - mrcnn_bbox_loss: 0.1703 - mrcnn_mask_loss: 0.2103\n",
      "Epoch 12/20\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.9947 - rpn_class_loss: 0.0667 - rpn_bbox_loss: 0.3332 - mrcnn_class_loss: 0.2194 - mrcnn_bbox_loss: 0.1666 - mrcnn_mask_loss: 0.2089\n",
      "Epoch 13/20\n",
      "60/60 [==============================] - 72s 1s/step - loss: 0.8615 - rpn_class_loss: 0.0580 - rpn_bbox_loss: 0.2938 - mrcnn_class_loss: 0.1866 - mrcnn_bbox_loss: 0.1457 - mrcnn_mask_loss: 0.1774\n",
      "Epoch 14/20\n",
      "60/60 [==============================] - 82s 1s/step - loss: 0.9131 - rpn_class_loss: 0.0629 - rpn_bbox_loss: 0.3212 - mrcnn_class_loss: 0.1791 - mrcnn_bbox_loss: 0.1596 - mrcnn_mask_loss: 0.1903\n",
      "Epoch 15/20\n",
      "60/60 [==============================] - 76s 1s/step - loss: 0.8459 - rpn_class_loss: 0.0543 - rpn_bbox_loss: 0.2973 - mrcnn_class_loss: 0.1886 - mrcnn_bbox_loss: 0.1400 - mrcnn_mask_loss: 0.1657\n",
      "Epoch 16/20\n",
      "60/60 [==============================] - 81s 1s/step - loss: 0.7965 - rpn_class_loss: 0.0498 - rpn_bbox_loss: 0.2681 - mrcnn_class_loss: 0.1724 - mrcnn_bbox_loss: 0.1328 - mrcnn_mask_loss: 0.1734\n",
      "Epoch 17/20\n",
      "60/60 [==============================] - 76s 1s/step - loss: 0.7835 - rpn_class_loss: 0.0542 - rpn_bbox_loss: 0.2868 - mrcnn_class_loss: 0.1571 - mrcnn_bbox_loss: 0.1227 - mrcnn_mask_loss: 0.1628\n",
      "Epoch 18/20\n",
      "60/60 [==============================] - 88s 1s/step - loss: 0.8271 - rpn_class_loss: 0.0552 - rpn_bbox_loss: 0.3044 - mrcnn_class_loss: 0.1701 - mrcnn_bbox_loss: 0.1301 - mrcnn_mask_loss: 0.1672\n",
      "Epoch 19/20\n",
      "60/60 [==============================] - 73s 1s/step - loss: 0.7364 - rpn_class_loss: 0.0493 - rpn_bbox_loss: 0.2660 - mrcnn_class_loss: 0.1616 - mrcnn_bbox_loss: 0.1128 - mrcnn_mask_loss: 0.1467\n",
      "Epoch 20/20\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.8402 - rpn_class_loss: 0.0527 - rpn_bbox_loss: 0.2944 - mrcnn_class_loss: 0.1784 - mrcnn_bbox_loss: 0.1457 - mrcnn_mask_loss: 0.1689\n",
      "\n",
      "Starting at epoch 20. LR=5e-05\n",
      "\n",
      "Checkpoint Path: C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\logs\\monuseg_5fold_coco_dist_h_tissue_img220210703T1151\\mask_rcnn_monuseg_5fold_coco_dist_h_tissue_img2_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/35\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.8135 - rpn_class_loss: 0.0504 - rpn_bbox_loss: 0.2718 - mrcnn_class_loss: 0.1830 - mrcnn_bbox_loss: 0.1468 - mrcnn_mask_loss: 0.1615\n",
      "Epoch 22/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\keras\\callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 73s 1s/step - loss: 0.7070 - rpn_class_loss: 0.0398 - rpn_bbox_loss: 0.2393 - mrcnn_class_loss: 0.1619 - mrcnn_bbox_loss: 0.1213 - mrcnn_mask_loss: 0.1446\n",
      "Epoch 23/35\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.6688 - rpn_class_loss: 0.0425 - rpn_bbox_loss: 0.2356 - mrcnn_class_loss: 0.1375 - mrcnn_bbox_loss: 0.1082 - mrcnn_mask_loss: 0.1451\n",
      "Epoch 24/35\n",
      "60/60 [==============================] - 71s 1s/step - loss: 0.7075 - rpn_class_loss: 0.0450 - rpn_bbox_loss: 0.2326 - mrcnn_class_loss: 0.1599 - mrcnn_bbox_loss: 0.1220 - mrcnn_mask_loss: 0.1481\n",
      "Epoch 25/35\n",
      "60/60 [==============================] - 79s 1s/step - loss: 0.7456 - rpn_class_loss: 0.0429 - rpn_bbox_loss: 0.2543 - mrcnn_class_loss: 0.1598 - mrcnn_bbox_loss: 0.1405 - mrcnn_mask_loss: 0.1482\n",
      "Epoch 26/35\n",
      "60/60 [==============================] - 74s 1s/step - loss: 0.7016 - rpn_class_loss: 0.0388 - rpn_bbox_loss: 0.2153 - mrcnn_class_loss: 0.1714 - mrcnn_bbox_loss: 0.1279 - mrcnn_mask_loss: 0.1482\n",
      "Epoch 27/35\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.7312 - rpn_class_loss: 0.0446 - rpn_bbox_loss: 0.2350 - mrcnn_class_loss: 0.1825 - mrcnn_bbox_loss: 0.1279 - mrcnn_mask_loss: 0.1413\n",
      "Epoch 28/35\n",
      "60/60 [==============================] - 77s 1s/step - loss: 0.6603 - rpn_class_loss: 0.0437 - rpn_bbox_loss: 0.2008 - mrcnn_class_loss: 0.1627 - mrcnn_bbox_loss: 0.1111 - mrcnn_mask_loss: 0.1421\n",
      "Epoch 29/35\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.7834 - rpn_class_loss: 0.0464 - rpn_bbox_loss: 0.2643 - mrcnn_class_loss: 0.1781 - mrcnn_bbox_loss: 0.1397 - mrcnn_mask_loss: 0.1549\n",
      "Epoch 30/35\n",
      "60/60 [==============================] - 78s 1s/step - loss: 0.7739 - rpn_class_loss: 0.0499 - rpn_bbox_loss: 0.2532 - mrcnn_class_loss: 0.1769 - mrcnn_bbox_loss: 0.1400 - mrcnn_mask_loss: 0.1540\n",
      "Epoch 31/35\n",
      "60/60 [==============================] - 82s 1s/step - loss: 0.6822 - rpn_class_loss: 0.0383 - rpn_bbox_loss: 0.2124 - mrcnn_class_loss: 0.1606 - mrcnn_bbox_loss: 0.1234 - mrcnn_mask_loss: 0.1475\n",
      "Epoch 32/35\n",
      "60/60 [==============================] - 76s 1s/step - loss: 0.7519 - rpn_class_loss: 0.0404 - rpn_bbox_loss: 0.2397 - mrcnn_class_loss: 0.1748 - mrcnn_bbox_loss: 0.1401 - mrcnn_mask_loss: 0.1570\n",
      "Epoch 33/35\n",
      "60/60 [==============================] - 77s 1s/step - loss: 0.7920 - rpn_class_loss: 0.0473 - rpn_bbox_loss: 0.2831 - mrcnn_class_loss: 0.1582 - mrcnn_bbox_loss: 0.1476 - mrcnn_mask_loss: 0.1559\n",
      "Epoch 34/35\n",
      "60/60 [==============================] - 79s 1s/step - loss: 0.6392 - rpn_class_loss: 0.0354 - rpn_bbox_loss: 0.1881 - mrcnn_class_loss: 0.1546 - mrcnn_bbox_loss: 0.1142 - mrcnn_mask_loss: 0.1468\n",
      "Epoch 35/35\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.6868 - rpn_class_loss: 0.0370 - rpn_bbox_loss: 0.2225 - mrcnn_class_loss: 0.1574 - mrcnn_bbox_loss: 0.1257 - mrcnn_mask_loss: 0.1441\n",
      "\n",
      "Starting at epoch 35. LR=1e-05\n",
      "\n",
      "Checkpoint Path: C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\logs\\monuseg_5fold_coco_dist_h_tissue_img220210703T1151\\mask_rcnn_monuseg_5fold_coco_dist_h_tissue_img2_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.7081 - rpn_class_loss: 0.0399 - rpn_bbox_loss: 0.2539 - mrcnn_class_loss: 0.1465 - mrcnn_bbox_loss: 0.1252 - mrcnn_mask_loss: 0.1426\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\keras\\callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 73s 1s/step - loss: 0.6692 - rpn_class_loss: 0.0359 - rpn_bbox_loss: 0.2232 - mrcnn_class_loss: 0.1452 - mrcnn_bbox_loss: 0.1221 - mrcnn_mask_loss: 0.1428\n",
      "Epoch 38/50\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.6929 - rpn_class_loss: 0.0388 - rpn_bbox_loss: 0.2132 - mrcnn_class_loss: 0.1574 - mrcnn_bbox_loss: 0.1316 - mrcnn_mask_loss: 0.1519\n",
      "Epoch 39/50\n",
      "60/60 [==============================] - 73s 1s/step - loss: 0.7225 - rpn_class_loss: 0.0378 - rpn_bbox_loss: 0.2456 - mrcnn_class_loss: 0.1549 - mrcnn_bbox_loss: 0.1376 - mrcnn_mask_loss: 0.1465\n",
      "Epoch 40/50\n",
      "60/60 [==============================] - 84s 1s/step - loss: 0.6558 - rpn_class_loss: 0.0388 - rpn_bbox_loss: 0.2105 - mrcnn_class_loss: 0.1355 - mrcnn_bbox_loss: 0.1311 - mrcnn_mask_loss: 0.1399\n",
      "Epoch 41/50\n",
      "60/60 [==============================] - 74s 1s/step - loss: 0.6177 - rpn_class_loss: 0.0336 - rpn_bbox_loss: 0.1989 - mrcnn_class_loss: 0.1366 - mrcnn_bbox_loss: 0.1116 - mrcnn_mask_loss: 0.1369\n",
      "Epoch 42/50\n",
      "60/60 [==============================] - 76s 1s/step - loss: 0.5757 - rpn_class_loss: 0.0249 - rpn_bbox_loss: 0.1866 - mrcnn_class_loss: 0.1258 - mrcnn_bbox_loss: 0.1049 - mrcnn_mask_loss: 0.1335\n",
      "Epoch 43/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 0.7091 - rpn_class_loss: 0.0402 - rpn_bbox_loss: 0.2392 - mrcnn_class_loss: 0.1621 - mrcnn_bbox_loss: 0.1246 - mrcnn_mask_loss: 0.1430\n",
      "Epoch 44/50\n",
      "60/60 [==============================] - 80s 1s/step - loss: 0.6729 - rpn_class_loss: 0.0395 - rpn_bbox_loss: 0.2497 - mrcnn_class_loss: 0.1355 - mrcnn_bbox_loss: 0.1158 - mrcnn_mask_loss: 0.1324\n",
      "Epoch 45/50\n",
      "60/60 [==============================] - 78s 1s/step - loss: 0.6480 - rpn_class_loss: 0.0337 - rpn_bbox_loss: 0.1887 - mrcnn_class_loss: 0.1537 - mrcnn_bbox_loss: 0.1294 - mrcnn_mask_loss: 0.1424\n",
      "Epoch 46/50\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.6458 - rpn_class_loss: 0.0326 - rpn_bbox_loss: 0.2030 - mrcnn_class_loss: 0.1421 - mrcnn_bbox_loss: 0.1264 - mrcnn_mask_loss: 0.1417\n",
      "Epoch 47/50\n",
      "60/60 [==============================] - 76s 1s/step - loss: 0.6585 - rpn_class_loss: 0.0378 - rpn_bbox_loss: 0.2234 - mrcnn_class_loss: 0.1387 - mrcnn_bbox_loss: 0.1188 - mrcnn_mask_loss: 0.1399\n",
      "Epoch 48/50\n",
      "60/60 [==============================] - 85s 1s/step - loss: 0.7384 - rpn_class_loss: 0.0391 - rpn_bbox_loss: 0.2513 - mrcnn_class_loss: 0.1621 - mrcnn_bbox_loss: 0.1371 - mrcnn_mask_loss: 0.1489\n",
      "Epoch 49/50\n",
      "60/60 [==============================] - 76s 1s/step - loss: 0.6185 - rpn_class_loss: 0.0336 - rpn_bbox_loss: 0.1932 - mrcnn_class_loss: 0.1397 - mrcnn_bbox_loss: 0.1121 - mrcnn_mask_loss: 0.1400\n",
      "Epoch 50/50\n",
      "60/60 [==============================] - 83s 1s/step - loss: 0.7132 - rpn_class_loss: 0.0397 - rpn_bbox_loss: 0.2339 - mrcnn_class_loss: 0.1548 - mrcnn_bbox_loss: 0.1398 - mrcnn_mask_loss: 0.1450\n",
      "Model Nr. 3 Fold:\n",
      "['TCGA-CH-5767-01Z-00-DX1', 'TCGA-G9-6336-01Z-00-DX1', 'TCGA-G9-6348-01Z-00-DX1', 'TCGA-G9-6356-01Z-00-DX1', 'TCGA-G9-6362-01Z-00-DX1', 'TCGA-G9-6363-01Z-00-DX1', 'TCGA-A7-A13E-01Z-00-DX1', 'TCGA-A7-A13F-01Z-00-DX1', 'TCGA-AR-A1AK-01Z-00-DX1', 'TCGA-AR-A1AS-01Z-00-DX1', 'TCGA-E2-A14V-01Z-00-DX1', 'TCGA-E2-A1B5-01Z-00-DX1', 'TCGA-B0-5698-01Z-00-DX1', 'TCGA-B0-5710-01Z-00-DX1', 'TCGA-B0-5711-01Z-00-DX1', 'TCGA-HE-7128-01Z-00-DX1', 'TCGA-HE-7129-01Z-00-DX1', 'TCGA-HE-7130-01Z-00-DX1', 'TCGA-KB-A93J-01A-01-TS1', 'TCGA-RD-A8N9-01A-01-TS1', 'TCGA-AY-A8YK-01A-01-TS1', 'TCGA-NH-A8F7-01A-01-TS1', 'TCGA-DK-A2I6-01A-01-TS1', 'TCGA-G2-A2EK-01A-02-TSB']\n",
      "Loding model from: C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\mask_rcnn_coco.h5\n",
      "\n",
      "Starting at epoch 0. LR=0.0002\n",
      "\n",
      "Checkpoint Path: C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\logs\\monuseg_5fold_coco_dist_h_tissue_img320210703T1258\\mask_rcnn_monuseg_5fold_coco_dist_h_tissue_img3_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "PREPROC                (Conv2D)\n",
      "conv1                  (Conv2D)\n",
      "In model:  rpn_model\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "c:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60/60 [==============================] - 85s 1s/step - loss: 3.6964 - rpn_class_loss: 0.9474 - rpn_bbox_loss: 1.4498 - mrcnn_class_loss: 0.0633 - mrcnn_bbox_loss: 0.7120 - mrcnn_mask_loss: 0.5239\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\tensorlflow1.14\\lib\\site-packages\\keras\\callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/60 [=============>................] - ETA: 45s - loss: 3.1556 - rpn_class_loss: 0.8786 - rpn_bbox_loss: 1.1941 - mrcnn_class_loss: 0.0497 - mrcnn_bbox_loss: 0.5846 - mrcnn_mask_loss: 0.4485"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[600,256,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_4/Adam/gradients/mrcnn_mask_2/convolution_grad/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2360f1d865f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0maugmentation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             layers=r\"(PREPROC)|(conv1.*)|(mrcnn\\_.*)\")\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         model.train(dataset_train, dataset_val,\n",
      "\u001b[1;32m~\\GitHub\\Mask_RCNN_Thesis\\mrcnn\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources, use_randaugment)\u001b[0m\n\u001b[0;32m   2913\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2914\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2915\u001b[1;33m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2916\u001b[0m         )\n\u001b[0;32m   2917\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1658\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\tensorlflow1.14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[600,256,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_4/Adam/gradients/mrcnn_mask_2/convolution_grad/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "config = Monuseg_dist.MonusegDIST_HConfig()\n",
    "config.VALIDATION_STEPS = 0\n",
    "i = 0\n",
    "\n",
    "for fold in fold_list:\n",
    "    # Used to choose model fold number\n",
    "    if i >= 2:   \n",
    "        print(\"Model Nr. {} Fold:\".format(i))\n",
    "        print(fold)\n",
    "        dataset_train = Monuseg_dist.MonusegDISTDataset()\n",
    "        dataset_val = Monuseg_dist.MonusegDISTDataset()\n",
    "        dataset_train.add_class(\"Monuseg\", 1, \"nucleus\")\n",
    "        # Fill with the train samples\n",
    "        for _n in fold:\n",
    "            dataset_train.add_image(source = \"Monuseg\", image_id = _n, path = dict_names[_n])\n",
    "        dataset_train.prepare()\n",
    "        \n",
    "        config.NAME = \"Monuseg_5Fold_COCO_DIST_H_TISSUE_IMG\" + str(i)\n",
    "        \n",
    "        with tf.device(DEVICE):\n",
    "            model = modellib.MaskRCNN(mode=TEST_MODE, model_dir=MODEL_DIR, config=config, verbose = False)\n",
    "        #wp = model.find_last()\n",
    "        wp = COCO_PATH\n",
    "        #wp = r\"C:\\Users\\User\\GitHub\\Mask_RCNN_Thesis\\logs\\pannuke model20210622T1625\\mask_rcnn_pannuke model_0036.h5\"\n",
    "        \n",
    "        print(\"Loding model from: {}\".format(wp))\n",
    "        model.load_weights(wp, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                \"mrcnn_bbox\", \"mrcnn_mask\"])        \n",
    "        #model.load_weights(wp, by_name = True)\n",
    "        \n",
    "        \n",
    "        #n_epoch = 50\n",
    "        #print(\"Train all layers\")\n",
    "        #model.train(dataset_train, dataset_val,\n",
    "        #       learning_rate=config.LEARNING_RATE,\n",
    "        #        epochs=n_epoch,\n",
    "        #        augmentation=augmentation,\n",
    "        #        layers='all')\n",
    "        \n",
    "        model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE*2,\n",
    "            epochs=5,\n",
    "            augmentation=augmentation,\n",
    "            layers=r\"(PREPROC)|(conv1.*)|(mrcnn\\_.*)\")\n",
    "\n",
    "        model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE,\n",
    "            epochs=35+5,\n",
    "            augmentation=augmentation,\n",
    "            layers=\"all\")\n",
    "\n",
    "        model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE * 0.5,\n",
    "            epochs=40+5,\n",
    "            augmentation=augmentation,\n",
    "            layers='5+')\n",
    "\n",
    "        model.train(dataset_train, dataset_val,\n",
    "            learning_rate=config.LEARNING_RATE * 0.1,\n",
    "            epochs=40+5,\n",
    "            augmentation=augmentation,\n",
    "            layers='heads')\n",
    "\n",
    "\n",
    "\n",
    "        del model\n",
    "    i = i+1        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
